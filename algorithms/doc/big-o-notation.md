# Big-O Notation

In computer science, big O notation is used to classify algorithms according to how their run time or space requirements 
grow as the input size grows. In analytic number theory, big O notation is often used to express a bound on 
the difference between an arithmetical function and a better understood approximation; a famous example of such 
a difference is the remainder term in the prime number theorem.

Big O notation characterizes functions according to their growth rates: different functions with the same growth rate 
may be represented using the same O notation.

## Characteristics

- O(1) - Constant
- O(logn) - Logarithmic
- O(n) - Linear
- O(nlogn) - n log-star n
- O(n^2) - Quadratic

## Links

* [Big O Notation](https://en.wikipedia.org/wiki/Big_O_notation)
